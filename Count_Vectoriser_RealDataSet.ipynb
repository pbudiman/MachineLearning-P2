{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solar-maximum",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER - Real Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-walker",
   "metadata": {},
   "source": [
    "### Raw Train & Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_file = \"./COMP30027_2021_Project2_datasets/recipe_train.csv\"\n",
    "test_file = \"./COMP30027_2021_Project2_datasets/recipe_test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "X_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "\n",
    "test_data = pd.read_csv(test_file)\n",
    "X_test = test_data.iloc[:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-diving",
   "metadata": {},
   "source": [
    "### Count Vectoriser for text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comic-kidney",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import scipy \n",
    "\n",
    "# Get the sparse matrix of the Bag-of-Word representation of text features for training data\n",
    "\n",
    "count_vec_folder = './COMP30027_2021_Project2_datasets/recipe_text_features_countvec/'\n",
    "\n",
    "# TRAIN & TEST DATASET - NAME\n",
    "vocab_name = pickle.load(open(count_vec_folder+'train_name_countvectorizer.pkl', \"rb\"))\n",
    "train_name_matrix = scipy.sparse.load_npz(count_vec_folder +'train_name_vec.npz')\n",
    "test_name_matrix = scipy.sparse.load_npz(count_vec_folder +'test_name_vec.npz')\n",
    "df_train_name = pd.DataFrame(train_name_matrix.todense(),columns = vocab_name.get_feature_names())\n",
    "df_test_name = pd.DataFrame(test_name_matrix.todense(),columns = vocab_name.get_feature_names())\n",
    "\n",
    "# TRAIN & TEST DATASET - STEPS\n",
    "vocab_steps = pickle.load(open(count_vec_folder + 'train_steps_countvectorizer.pkl', \"rb\"))\n",
    "train_steps_matrix = scipy.sparse.load_npz(count_vec_folder +'train_steps_vec.npz')\n",
    "test_steps_matrix = scipy.sparse.load_npz(count_vec_folder +'test_steps_vec.npz')\n",
    "df_train_steps = pd.DataFrame(train_steps_matrix.todense(),columns = vocab_steps.get_feature_names())\n",
    "df_test_steps = pd.DataFrame(test_steps_matrix.todense(),columns = vocab_steps.get_feature_names())\n",
    "\n",
    "# TRAIN & TEST DATASET- INGREDIENTS\n",
    "vocab_ingr = pickle.load(open(count_vec_folder + 'train_ingr_countvectorizer.pkl', \"rb\"))\n",
    "train_ingr_matrix = scipy.sparse.load_npz(count_vec_folder +'train_ingr_vec.npz')\n",
    "test_ingr_matrix = scipy.sparse.load_npz(count_vec_folder +'test_ingr_vec.npz')\n",
    "df_train_ingr = pd.DataFrame(train_ingr_matrix.todense(),columns = vocab_ingr.get_feature_names())\n",
    "df_test_ingr = pd.DataFrame(test_ingr_matrix.todense(),columns = vocab_ingr.get_feature_names())\n",
    "\n",
    "# TRAIN & TEST DATASET- N_STEPS\n",
    "train_n_steps = pd.DataFrame(X_train.n_steps)\n",
    "train_n_steps.reset_index(drop=True, inplace=True)\n",
    "test_n_steps = pd.DataFrame(X_test.n_steps)\n",
    "test_n_steps.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# TRAIN & TEST DATASET- N_INGREDIENTS\n",
    "train_n_ingredients = pd.DataFrame(X_train.n_ingredients)\n",
    "train_n_ingredients.reset_index(drop=True, inplace=True)\n",
    "test_n_ingredients = pd.DataFrame(X_test.n_ingredients)\n",
    "test_n_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ALL FEATURES AND THEIR MATRICES\n",
    "train = pd.concat([df_train_name,df_train_steps,df_train_ingr,train_n_steps,train_n_ingredients],axis=1)\n",
    "test = pd.concat([df_test_name,df_test_steps,df_test_ingr,test_n_steps,test_n_ingredients],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-advocacy",
   "metadata": {},
   "source": [
    "### Individual Classifiers - All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "julian-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MNB\n",
      "START  1621514011.905874\n",
      "END  1621514102.371785\n",
      "MNB Time: 90.46591091156006  s\n",
      "Decision Tree\n",
      "START  1621514102.547482\n",
      "END  1621514249.014076\n",
      "Decision Tree Time: 146.46659398078918  s\n",
      "Logistic Regression\n",
      "START  1621514249.061354\n",
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "END  1621516298.5528681\n",
      "Logistic Regression Time: 2049.4915142059326  s\n"
     ]
    }
   ],
   "source": [
    "# Predict using each individual classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "models = [MultinomialNB(),\n",
    "          DecisionTreeClassifier(),\n",
    "          LogisticRegression()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    print(title)\n",
    "    start = time.time()\n",
    "    print(\"START \",start)\n",
    "    model.fit(train,y_train)\n",
    "    result = model.predict(test)\n",
    "    end = time.time()\n",
    "    print(\"END \",end)\n",
    "    t = end - start\n",
    "    print(title,'Time:', t,\" s\")\n",
    "    df_res_full = pd.DataFrame(result, columns = ['duration_label'])\n",
    "    df_res_full.index = df_res_full.index + 1\n",
    "    df_res_full.index.name='id'\n",
    "    df_res_full.to_csv('df_CV_res_'+title+'_full.csv')\n",
    "    "
   ]
  },
  {
   "source": [
    "### STACKING - Full Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "classifiers = [('MNB',MultinomialNB()),('DT',DecisionTreeClassifier())]\n",
    "stack_clf = StackingClassifier(estimators=classifiers, final_estimator=LogisticRegression(),cv=5).fit(train, y_train)\n",
    "result = stack_clf.predict(test)\n",
    "df_res = pd.DataFrame(result, columns = ['duration_label'])\n",
    "df_res.index = df_res.index + 1\n",
    "df_res.index.name='id'\n",
    "df_res.to_csv('df_CV_stack_sklearn_Log_Reg.csv')"
   ]
  },
  {
   "source": [
    "### CHI SQUARE , K=1000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "traditional-circulation",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start  1621528395.0011818\n",
      "end  1621528436.596156\n",
      "time:  41.59497404098511\n"
     ]
    }
   ],
   "source": [
    "# KBEST -chi2\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "start = time.time()\n",
    "print(\"start \",start)\n",
    "kbest_chi2 = SelectKBest(chi2, k=1000).fit(train, y_train)\n",
    "X_train_kbest_chi2 = kbest_chi2.transform(train)\n",
    "X_test_kbest_chi2 = kbest_chi2.transform(test)\n",
    "end= time.time()\n",
    "print(\"end \",end)\n",
    "print(\"time: \",end-start)\n"
   ]
  },
  {
   "source": [
    "### Individual Classifiers - CHI SQUARE, K=1000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pregnant-palestine",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MNB\n",
      "START  1621517404.8140302\n",
      "END  1621517405.427587\n",
      "MNB Time: 0.6135568618774414  s\n",
      "Decision Tree\n",
      "START  1621517405.4564962\n",
      "END  1621517415.3387551\n",
      "Decision Tree Time: 9.882258892059326  s\n",
      "Logistic Regression\n",
      "START  1621517415.3659468\n",
      "END  1621517425.815221\n",
      "Logistic Regression Time: 10.44927430152893  s\n",
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [MultinomialNB(),\n",
    "          DecisionTreeClassifier(),\n",
    "          LogisticRegression()]\n",
    "titles = ['MNB',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    print(title)\n",
    "    start = time.time()\n",
    "    print(\"START \",start)\n",
    "    model.fit(X_train_kbest_chi2,y_train)\n",
    "    result = model.predict(X_test_kbest_chi2)\n",
    "    end = time.time()\n",
    "    print(\"END \",end)\n",
    "    t = end - start\n",
    "    print(title,'Time:', t,\" s\")\n",
    "    df_res_full = pd.DataFrame(result, columns = ['duration_label'])\n",
    "    df_res_full.index = df_res_full.index + 1\n",
    "    df_res_full.index.name='id'\n",
    "    df_res_full.to_csv('df_CV_res_chi2_'+title+'_full.csv')\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Stacking - CHI SQUARE , K=1000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "classifiers = [('MNB',MultinomialNB()),('DT',DecisionTreeClassifier())]\n",
    "stack_clf = StackingClassifier(estimators=classifiers, final_estimator=LogisticRegression(),cv=5).fit(train, y_train)\n",
    "result = stack_clf.predict(test)\n",
    "df_res = pd.DataFrame(result, columns = ['duration_label'])\n",
    "df_res.index = df_res.index + 1\n",
    "df_res.index.name='id'\n",
    "df_res.to_csv('df_CV_chi2_stack_sklearn_Log_Reg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd0d1736c05fe10e97bff6b3f226078a77ebc9caa91540e72cc2b3b64c309fda00b",
   "display_name": "Python 3.7.3 64-bit ('3.7.3': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loose-monday",
   "metadata": {},
   "source": [
    "### Count Vectoriser - Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "systematic-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26800, 26272)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Test to see approximate accuracy by splitting the training data to train and test data = 7:3\n",
    "train_file = \"./COMP30027_2021_Project2_datasets/recipe_train.csv\"\n",
    "train_data = pd.read_csv(train_file)\n",
    "X_train_raw = train_data.iloc[:,:-1]\n",
    "y_train_raw = train_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_raw,y_train_raw,test_size=0.33)\n",
    "\n",
    "train_n_steps = pd.DataFrame(X_train.n_steps)\n",
    "train_n_steps.reset_index(drop=True, inplace=True)\n",
    "test_n_steps = pd.DataFrame(X_test.n_steps)\n",
    "test_n_steps.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_n_ingredients = pd.DataFrame(X_train.n_ingredients)\n",
    "train_n_ingredients.reset_index(drop=True, inplace=True)\n",
    "test_n_ingredients = pd.DataFrame(X_test.n_ingredients)\n",
    "test_n_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# count vectorizer on feature 'name'\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "X_train_name = vec.fit_transform(X_train.name)\n",
    "X_test_name = vec.transform(X_test.name)\n",
    "df_train_name = pd.DataFrame(X_train_name.todense(),columns = vec.get_feature_names())\n",
    "df_test_name = pd.DataFrame(X_test_name.todense(),columns = vec.get_feature_names())\n",
    "\n",
    "# count vectorizer on feature 'steps'\n",
    "X_train_steps = vec.fit_transform(X_train.steps)\n",
    "X_test_steps = vec.transform(X_test.steps)\n",
    "df_train_steps = pd.DataFrame(X_train_steps.todense(),columns = vec.get_feature_names())\n",
    "df_test_steps = pd.DataFrame(X_test_steps.todense(),columns = vec.get_feature_names())\n",
    "\n",
    "\n",
    "# count vectorizer on feature 'ingredients'\n",
    "X_train_ing = vec.fit_transform(X_train.ingredients)\n",
    "X_test_ing = vec.transform(X_test.ingredients)\n",
    "df_train_ing = pd.DataFrame(X_train_ing.todense(),columns = vec.get_feature_names())\n",
    "df_test_ing = pd.DataFrame(X_test_ing.todense(),columns = vec.get_feature_names())\n",
    "\n",
    "# put all into one dataframe\n",
    "train = pd.concat([df_train_name, df_train_steps,df_train_ing,train_n_steps,train_n_ingredients],axis=1)\n",
    "test = pd.concat([df_test_name, df_test_steps,df_test_ing,test_n_steps,test_n_ingredients],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "patient-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STACKING FROM W8 Prac\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        assert yhats.shape[0] == X.shape[0]\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)     \n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-convenience",
   "metadata": {},
   "source": [
    "#### Individual Classifiers -  Full Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constitutional-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "START  1621410722.59531\n",
      "END  1621410786.0641549\n",
      "MNB Accuracy: 0.7396212121212121 Time: 63.46884489059448  s\n",
      "LinearSVC\n",
      "START  1621410786.168375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END  1621410862.7662442\n",
      "LinearSVC Accuracy: 0.7507575757575757 Time: 76.59786915779114  s\n",
      "Decision Tree\n",
      "START  1621410862.772287\n",
      "END  1621410934.6870122\n",
      "Decision Tree Accuracy: 0.7366666666666667 Time: 71.9147253036499  s\n",
      "Logistic Regression\n",
      "START  1621410934.6885839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END  1621411650.031492\n",
      "Logistic Regression Accuracy: 0.7907575757575758 Time: 715.3429081439972  s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "models = [MultinomialNB(),\n",
    "          svm.LinearSVC(),\n",
    "          DecisionTreeClassifier(),\n",
    "          LogisticRegression()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'LinearSVC',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    print(title)\n",
    "    start = time.time()\n",
    "    print(\"START \",start)\n",
    "    model.fit(train,y_train)\n",
    "    acc = model.score(test,y_test)\n",
    "    end = time.time()\n",
    "    print(\"END \",end)\n",
    "    t = end - start\n",
    "    print(title, \"Accuracy:\",acc, 'Time:', t,\" s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-aluminum",
   "metadata": {},
   "source": [
    "#### Stacking - Full Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colonial-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - Start  1621411833.8975801\n",
      "Meta learner: Logistic Regression - End  1621411962.687659\n",
      "Accuracy  0.7346969696969697\n",
      "Time: 128.7900788784027  s\n"
     ]
    }
   ],
   "source": [
    "# Meta Learner : Logistic Regression \n",
    "# Base Learners : DT + MNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "classifiers = [MultinomialNB(),\n",
    "          DecisionTreeClassifier()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'Decision Tree']\n",
    "\n",
    "meta_classifier_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)\n",
    "start = time.time()\n",
    "print(\"Meta learner: Logistic Regression - Start \",start)\n",
    "stacker_lr.fit(train, y_train)\n",
    "acc = stacker_lr.score(test,y_test)\n",
    "end = time.time()\n",
    "print(\"Meta learner: Logistic Regression - End \",end)\n",
    "print(\"Accuracy \",acc)\n",
    "t = end - start\n",
    "print('Time:', t,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modern-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - Start  1621412250.669444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - End  1621413118.7024372\n",
      "Accuracy  0.738030303030303\n",
      "Time: 868.0329930782318  s\n"
     ]
    }
   ],
   "source": [
    "# Meta Learner : Logistic Regression \n",
    "# Base Learners : DT + MNB + LogReg\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "classifiers = [MultinomialNB(),\n",
    "                DecisionTreeClassifier(),\n",
    "                LogisticRegression()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "meta_classifier_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)\n",
    "start = time.time()\n",
    "print(\"Meta learner: Logistic Regression - Start \",start)\n",
    "stacker_lr.fit(train, y_train)\n",
    "acc = stacker_lr.score(test,y_test)\n",
    "end = time.time()\n",
    "print(\"Meta learner: Logistic Regression - End \",end)\n",
    "print(\"Accuracy \",acc)\n",
    "t = end - start\n",
    "print('Time:', t,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-apparel",
   "metadata": {},
   "source": [
    "### CHI SQUARE - K Best , k=1000, chi^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indian-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import time\n",
    "from time import ctime\n",
    "\n",
    "kbest_chi2 = SelectKBest(chi2, k=1000).fit(train, y_train)\n",
    "X_train_kbest_chi2 = kbest_chi2.transform(train)\n",
    "X_test_kbest_chi2 = kbest_chi2.transform(test)\n"
   ]
  },
  {
   "source": [
    "### Individual Classifiers - CHI SQUARE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floppy-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "START  1621415143.89592\n",
      "END  1621415144.485644\n",
      "MNB Accuracy: 0.706060606060606 Time: 0.589724063873291  s\n",
      "LinearSVC\n",
      "START  1621415144.4858701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END  1621415160.1332102\n",
      "LinearSVC Accuracy: 0.8024242424242424 Time: 15.647340059280396  s\n",
      "Decision Tree\n",
      "START  1621415160.1334689\n",
      "END  1621415165.569706\n",
      "Decision Tree Accuracy: 0.7315909090909091 Time: 5.436237096786499  s\n",
      "Logistic Regression\n",
      "START  1621415165.569865\n",
      "END  1621415173.124801\n",
      "Logistic Regression Accuracy: 0.8043181818181818 Time: 7.554935932159424  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [MultinomialNB(),\n",
    "          svm.LinearSVC(),\n",
    "          DecisionTreeClassifier(),\n",
    "          LogisticRegression()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'LinearSVC',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    print(title)\n",
    "    start = time.time()\n",
    "    print(\"START \",start)\n",
    "    model.fit(X_train_kbest_chi2,y_train)\n",
    "    acc = model.score(X_test_kbest_chi2,y_test)\n",
    "    end = time.time()\n",
    "    print(\"END \",end)\n",
    "    t = end - start\n",
    "    print(title, \"Accuracy:\",acc, 'Time:', t,\" s\")\n"
   ]
  },
  {
   "source": [
    "### Stacking - CHI SQUARE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nearby-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - Start  1621415265.917923\n",
      "Meta learner: Logistic Regression - End  1621415271.678397\n",
      "Accuracy  0.7287121212121213\n",
      "Time: 5.760473966598511  s\n"
     ]
    }
   ],
   "source": [
    "# Meta Learner : Logistic Regression \n",
    "# Base Learners : DT + MNB\n",
    "\n",
    "classifiers = [MultinomialNB(),\n",
    "          DecisionTreeClassifier()]\n",
    "\n",
    "titles = ['MNB',\n",
    "          'Decision Tree']\n",
    "\n",
    "meta_classifier_lr = LogisticRegression()\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)\n",
    "start = time.time()\n",
    "print(\"Meta learner: Logistic Regression - Start \",start)\n",
    "stacker_lr.fit(X_train_kbest_chi2, y_train)\n",
    "acc = stacker_lr.score(X_test_kbest_chi2,y_test)\n",
    "end = time.time()\n",
    "print(\"Meta learner: Logistic Regression - End \",end)\n",
    "print(\"Accuracy \",acc)\n",
    "t = end - start\n",
    "print('Time:', t,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daily-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - Start  1621415443.963565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciaangelica/.pyenv/versions/3.7.3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta learner: Logistic Regression - End  1621415456.7150111\n",
      "Accuracy  0.7253030303030303\n",
      "Time: 12.751446008682251  s\n"
     ]
    }
   ],
   "source": [
    "# Meta Learner : Logistic Regression \n",
    "# Base Learners : DT + MNB + LogReg\n",
    "\n",
    "classifiers1 = [MultinomialNB(),\n",
    "                DecisionTreeClassifier(),\n",
    "                LogisticRegression()]\n",
    "\n",
    "titles1 = ['MNB',\n",
    "          'Decision Tree',\n",
    "          'Logistic Regression']\n",
    "\n",
    "meta_classifier_lr1 = LogisticRegression()\n",
    "stacker_lr1 = StackingClassifier(classifiers1, meta_classifier_lr1)\n",
    "start = time.time()\n",
    "print(\"Meta learner: Logistic Regression - Start \",start)\n",
    "stacker_lr1.fit(X_train_kbest_chi2, y_train)\n",
    "acc = stacker_lr1.score(X_test_kbest_chi2,y_test)\n",
    "end = time.time()\n",
    "print(\"Meta learner: Logistic Regression - End \",end)\n",
    "print(\"Accuracy \",acc)\n",
    "t = end - start\n",
    "print('Time:', t,\" s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}